{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeniGaus/NLP/blob/master/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_xQprdtX3m8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9988794e-0a7a-4685-ac2f-84142cac5d00"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131304 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZpeC4Etj3tJK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sx66_BGM3xvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "19b9a624-acaf-4fad-85f0-c9d003345bc6"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gzWse6_L342T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6rO3J4kW38sr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00b5e22a-b539-4b3c-f6ad-d513c2ca0b54"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/NLP"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_qa.txt  train_qa.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "01PHSZaH2QH3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/NLP')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aatKUjH39hw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gH7VQEO4bWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(filepath):\n",
        "  data = []\n",
        "  with open(filepath,\"rb\") as fp:\n",
        "    data = pickle.load(fp)\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmUecVEn4gvr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = get_data(\"train_qa.txt\")\n",
        "test_data = get_data(\"test_qa.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zcbgtlXb2Zzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e2b5dc5-3ec9-4792-e5a1-c6229675b2a0"
      },
      "cell_type": "code",
      "source": [
        "print(f\"Train data: {type(train_data)}, {len(train_data)}\")\n",
        "print(f\"Test data: {type(test_data)}, {len(test_data)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data: <class 'list'>, 10000\n",
            "Test data: <class 'list'>, 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gs7mccYl64Yz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setting up Vocabulary of all words\n",
        "----------------------\n"
      ]
    },
    {
      "metadata": {
        "id": "aO3tQI1J6_-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "\n",
        "all_data = train_data + test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoWaacm_7IQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for story, query, ans in all_data:\n",
        "  vocab = vocab.union(set(story))\n",
        "  vocab = vocab.union(set(query))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9BZje1hr7b7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jfSM3Cwy29nk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "02e909a3-3f08-40ed-99bc-7d50535ed65a"
      },
      "cell_type": "code",
      "source": [
        "print(vocab)\n",
        "print(len(vocab))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Sandra', 'John', 'picked', 'put', 'bedroom', 'office', 'Is', 'in', 'football', 'there', 'milk', 'apple', 'Daniel', 'grabbed', 'to', 'the', 'dropped', 'yes', 'hallway', 'travelled', 'got', 'garden', 'no', 'left', 'went', 'down', 'bathroom', '.', 'journeyed', 'Mary', 'back', 'up', 'moved', 'took', 'discarded', 'kitchen', '?'}\n",
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ED-qvnAI9Dwp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add an extra space to hold 0 for Keras pad_sequences\n",
        "vocab_len = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSJSO5Yd_-bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "290a6286-e159-493f-e9b5-914bef308b22"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MXFMGI-wB-wF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVGHUa_ACNRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "b0af6db7-9883-4cee-efe0-b9393cf05e01"
      },
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 28,\n",
              " '?': 37,\n",
              " 'apple': 12,\n",
              " 'back': 31,\n",
              " 'bathroom': 27,\n",
              " 'bedroom': 5,\n",
              " 'daniel': 13,\n",
              " 'discarded': 35,\n",
              " 'down': 26,\n",
              " 'dropped': 17,\n",
              " 'football': 9,\n",
              " 'garden': 22,\n",
              " 'got': 21,\n",
              " 'grabbed': 14,\n",
              " 'hallway': 19,\n",
              " 'in': 8,\n",
              " 'is': 7,\n",
              " 'john': 2,\n",
              " 'journeyed': 29,\n",
              " 'kitchen': 36,\n",
              " 'left': 24,\n",
              " 'mary': 30,\n",
              " 'milk': 11,\n",
              " 'moved': 33,\n",
              " 'no': 23,\n",
              " 'office': 6,\n",
              " 'picked': 3,\n",
              " 'put': 4,\n",
              " 'sandra': 1,\n",
              " 'the': 16,\n",
              " 'there': 10,\n",
              " 'to': 15,\n",
              " 'took': 34,\n",
              " 'travelled': 20,\n",
              " 'up': 32,\n",
              " 'went': 25,\n",
              " 'yes': 18}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "UlCK3rKZCR8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,ques,ans in train_data:\n",
        "  train_story_text.append(story)\n",
        "  train_question_text.append(ques)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSBKz2y73dJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a5895a7-e111-4945-f71f-fb2b4c071a47"
      },
      "cell_type": "code",
      "source": [
        "print(f\"Story: {len(train_story_text)}\")\n",
        "print(f\"Questions: {len(train_question_text)}\")\n",
        "#print(f\"Story: {len(train_story_text)}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Story: 10000\n",
            "Questions: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kXVnqGlhDCh4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kN6ud7xi337d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "db829aad-66c9-4a48-de04-51508b6775a4"
      },
      "cell_type": "code",
      "source": [
        "print(train_story_text[0])\n",
        "print(train_story_seq[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.']\n",
            "[30, 33, 15, 16, 27, 28, 1, 29, 15, 16, 5, 28]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dCdfJtVdSUHu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z6dQFyh2SgHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Functionalize Vectorization\n",
        "----------------------\n"
      ]
    },
    {
      "metadata": {
        "id": "t5fd1urhRew2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "  '''\n",
        "  INPUT: \n",
        "    \n",
        "  data: consisting of Stories,Queries,and Answers\n",
        "  word_index: word index dictionary from tokenizer\n",
        "  max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "  max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "  OUTPUT:\n",
        "\n",
        "  Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "  answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "  output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "\n",
        "  Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "  '''\n",
        "\n",
        "    \n",
        "  # X = STORIES\n",
        "  X = []\n",
        "  # Xq = QUERY/QUESTION\n",
        "  Xq = []\n",
        "  # Y = CORRECT ANSWER\n",
        "  Y = []\n",
        "\n",
        "\n",
        "  for story, query, answer in data:\n",
        "    \n",
        "    # Grab the word index for every word in story\n",
        "    x = [word_index[word.lower()] for word in story]\n",
        "    # Grab the word index for every word in query\n",
        "    xq = [word_index[word.lower()] for word in query]\n",
        "\n",
        "    # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "    # Index 0 is reserved so we're going to use + 1\n",
        "    y = np.zeros(len(word_index) + 1)\n",
        "\n",
        "    # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "    #\n",
        "    y[word_index[answer]] = 1\n",
        "\n",
        "    # Append each set of story,query, and answer to their respective holding lists\n",
        "    X.append(x)\n",
        "    Xq.append(xq)\n",
        "    Y.append(y)\n",
        "\n",
        "  # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "\n",
        "  # RETURN TUPLE FOR UNPACKING\n",
        "  return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-HU9G-ZSqXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuyAKSCyWjaB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9vVewiaSwRq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the Model\n",
        "------\n"
      ]
    },
    {
      "metadata": {
        "id": "_lGrOoSTS0PJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "viG0PCm0TXTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUaBuxX9T64P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "08aa8fc5-63be-46d2-9ea0-d165ba201d19"
      },
      "cell_type": "code",
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-i8pn1DnVpgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZTVXo-s0W-06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugj-eb5gYd8j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Encode Sequences"
      ]
    },
    {
      "metadata": {
        "id": "8iTiag-PYhnz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fb4WWkULZcvs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "metadata": {
        "id": "PCKnhDTFY9NB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "match = dot([input_encoded_m, question_encoded], axes=(2,2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HOM-TNj2Zeb7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "metadata": {
        "id": "kk0JE9DFZdfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XpYvoIdRx6fL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AwRvWdjKyALp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1943a99c-76d3-4d78-dd71-f77805b5ae48"
      },
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "aFi5w66dyBVk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ouQJP83pyVdq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LgRor2L0H7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kimyvX0o0K3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "690c6baf-a5da-40fe-c9c3-811751932d57"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
            "                                                                 sequential_2[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OHxtq99q0OWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4236
        },
        "outputId": "a002487f-cba1-4227-cde1-8d62b681ee25"
      },
      "cell_type": "code",
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/120\n",
            "10000/10000 [==============================] - 8s 763us/step - loss: 0.9244 - acc: 0.4993 - val_loss: 0.6948 - val_acc: 0.5030\n",
            "Epoch 2/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.7053 - acc: 0.5004 - val_loss: 0.6950 - val_acc: 0.5030\n",
            "Epoch 3/120\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 0.6962 - acc: 0.5052 - val_loss: 0.6940 - val_acc: 0.5030\n",
            "Epoch 4/120\n",
            "10000/10000 [==============================] - 5s 479us/step - loss: 0.6953 - acc: 0.4959 - val_loss: 0.6932 - val_acc: 0.5030\n",
            "Epoch 5/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.6945 - acc: 0.5096 - val_loss: 0.6949 - val_acc: 0.4970\n",
            "Epoch 6/120\n",
            "10000/10000 [==============================] - 5s 499us/step - loss: 0.6947 - acc: 0.4963 - val_loss: 0.6935 - val_acc: 0.4970\n",
            "Epoch 7/120\n",
            "10000/10000 [==============================] - 5s 519us/step - loss: 0.6942 - acc: 0.5011 - val_loss: 0.6942 - val_acc: 0.4970\n",
            "Epoch 8/120\n",
            "10000/10000 [==============================] - 5s 482us/step - loss: 0.6942 - acc: 0.5021 - val_loss: 0.6943 - val_acc: 0.5030\n",
            "Epoch 9/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.6937 - acc: 0.5062 - val_loss: 0.6947 - val_acc: 0.4990\n",
            "Epoch 10/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.6929 - acc: 0.5199 - val_loss: 0.6951 - val_acc: 0.4880\n",
            "Epoch 11/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.6901 - acc: 0.5224 - val_loss: 0.6941 - val_acc: 0.4980\n",
            "Epoch 12/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.6836 - acc: 0.5338 - val_loss: 0.6840 - val_acc: 0.5270\n",
            "Epoch 13/120\n",
            "10000/10000 [==============================] - 5s 458us/step - loss: 0.6675 - acc: 0.5840 - val_loss: 0.6619 - val_acc: 0.6050\n",
            "Epoch 14/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.6490 - acc: 0.6161 - val_loss: 0.6315 - val_acc: 0.6290\n",
            "Epoch 15/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.6250 - acc: 0.6533 - val_loss: 0.6177 - val_acc: 0.6550\n",
            "Epoch 16/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.6011 - acc: 0.6842 - val_loss: 0.5633 - val_acc: 0.7250\n",
            "Epoch 17/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.5677 - acc: 0.7151 - val_loss: 0.5195 - val_acc: 0.7530\n",
            "Epoch 18/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.5410 - acc: 0.7351 - val_loss: 0.4950 - val_acc: 0.7680\n",
            "Epoch 19/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.5118 - acc: 0.7619 - val_loss: 0.4927 - val_acc: 0.7710\n",
            "Epoch 20/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.4956 - acc: 0.7731 - val_loss: 0.4783 - val_acc: 0.7850\n",
            "Epoch 21/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.4742 - acc: 0.7845 - val_loss: 0.4552 - val_acc: 0.7850\n",
            "Epoch 22/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.4584 - acc: 0.7884 - val_loss: 0.4325 - val_acc: 0.8040\n",
            "Epoch 23/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.4438 - acc: 0.7995 - val_loss: 0.4710 - val_acc: 0.7930\n",
            "Epoch 24/120\n",
            "10000/10000 [==============================] - 5s 508us/step - loss: 0.4360 - acc: 0.8030 - val_loss: 0.5048 - val_acc: 0.7740\n",
            "Epoch 25/120\n",
            "10000/10000 [==============================] - 5s 492us/step - loss: 0.4216 - acc: 0.8116 - val_loss: 0.4215 - val_acc: 0.8000\n",
            "Epoch 26/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.4174 - acc: 0.8108 - val_loss: 0.4137 - val_acc: 0.8060\n",
            "Epoch 27/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.4045 - acc: 0.8145 - val_loss: 0.4395 - val_acc: 0.8070\n",
            "Epoch 28/120\n",
            "10000/10000 [==============================] - 4s 444us/step - loss: 0.4015 - acc: 0.8165 - val_loss: 0.3977 - val_acc: 0.8170\n",
            "Epoch 29/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.3933 - acc: 0.8209 - val_loss: 0.4004 - val_acc: 0.8190\n",
            "Epoch 30/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.3784 - acc: 0.8287 - val_loss: 0.4049 - val_acc: 0.8210\n",
            "Epoch 31/120\n",
            "10000/10000 [==============================] - 5s 501us/step - loss: 0.3771 - acc: 0.8262 - val_loss: 0.3749 - val_acc: 0.8250\n",
            "Epoch 32/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.3683 - acc: 0.8331 - val_loss: 0.3760 - val_acc: 0.8270\n",
            "Epoch 33/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.3582 - acc: 0.8426 - val_loss: 0.3649 - val_acc: 0.8350\n",
            "Epoch 34/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.3550 - acc: 0.8424 - val_loss: 0.3652 - val_acc: 0.8290\n",
            "Epoch 35/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.3523 - acc: 0.8491 - val_loss: 0.3648 - val_acc: 0.8400\n",
            "Epoch 36/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.3464 - acc: 0.8503 - val_loss: 0.3551 - val_acc: 0.8270\n",
            "Epoch 37/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.3407 - acc: 0.8500 - val_loss: 0.3630 - val_acc: 0.8390\n",
            "Epoch 38/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.3432 - acc: 0.8540 - val_loss: 0.3541 - val_acc: 0.8350\n",
            "Epoch 39/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.3364 - acc: 0.8565 - val_loss: 0.3630 - val_acc: 0.8270\n",
            "Epoch 40/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.3297 - acc: 0.8594 - val_loss: 0.3503 - val_acc: 0.8440\n",
            "Epoch 41/120\n",
            "10000/10000 [==============================] - 5s 491us/step - loss: 0.3276 - acc: 0.8582 - val_loss: 0.3633 - val_acc: 0.8300\n",
            "Epoch 42/120\n",
            "10000/10000 [==============================] - 5s 504us/step - loss: 0.3233 - acc: 0.8599 - val_loss: 0.3563 - val_acc: 0.8420\n",
            "Epoch 43/120\n",
            "10000/10000 [==============================] - 5s 470us/step - loss: 0.3252 - acc: 0.8620 - val_loss: 0.3523 - val_acc: 0.8420\n",
            "Epoch 44/120\n",
            "10000/10000 [==============================] - 5s 478us/step - loss: 0.3167 - acc: 0.8628 - val_loss: 0.3599 - val_acc: 0.8260\n",
            "Epoch 45/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.3148 - acc: 0.8672 - val_loss: 0.3536 - val_acc: 0.8440\n",
            "Epoch 46/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.3180 - acc: 0.8627 - val_loss: 0.3431 - val_acc: 0.8460\n",
            "Epoch 47/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.3139 - acc: 0.8636 - val_loss: 0.3652 - val_acc: 0.8300\n",
            "Epoch 48/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.3107 - acc: 0.8678 - val_loss: 0.3623 - val_acc: 0.8440\n",
            "Epoch 49/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.3096 - acc: 0.8673 - val_loss: 0.3467 - val_acc: 0.8360\n",
            "Epoch 50/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.3043 - acc: 0.8698 - val_loss: 0.3552 - val_acc: 0.8340\n",
            "Epoch 51/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.3083 - acc: 0.8677 - val_loss: 0.3472 - val_acc: 0.8340\n",
            "Epoch 52/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.3058 - acc: 0.8698 - val_loss: 0.3673 - val_acc: 0.8320\n",
            "Epoch 53/120\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.3015 - acc: 0.8710 - val_loss: 0.3548 - val_acc: 0.8420\n",
            "Epoch 54/120\n",
            "10000/10000 [==============================] - 5s 481us/step - loss: 0.3078 - acc: 0.8680 - val_loss: 0.3578 - val_acc: 0.8310\n",
            "Epoch 55/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.3085 - acc: 0.8662 - val_loss: 0.3450 - val_acc: 0.8390\n",
            "Epoch 56/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.3003 - acc: 0.8711 - val_loss: 0.3537 - val_acc: 0.8410\n",
            "Epoch 57/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.3068 - acc: 0.8696 - val_loss: 0.3758 - val_acc: 0.8290\n",
            "Epoch 58/120\n",
            "10000/10000 [==============================] - 5s 466us/step - loss: 0.3003 - acc: 0.8716 - val_loss: 0.3666 - val_acc: 0.8310\n",
            "Epoch 59/120\n",
            "10000/10000 [==============================] - 5s 503us/step - loss: 0.2971 - acc: 0.8737 - val_loss: 0.3596 - val_acc: 0.8290\n",
            "Epoch 60/120\n",
            "10000/10000 [==============================] - 5s 487us/step - loss: 0.2908 - acc: 0.8757 - val_loss: 0.3627 - val_acc: 0.8280\n",
            "Epoch 61/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2991 - acc: 0.8736 - val_loss: 0.3789 - val_acc: 0.8340\n",
            "Epoch 62/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.2922 - acc: 0.8734 - val_loss: 0.3654 - val_acc: 0.8320\n",
            "Epoch 63/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.2856 - acc: 0.8762 - val_loss: 0.3600 - val_acc: 0.8290\n",
            "Epoch 64/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2938 - acc: 0.8742 - val_loss: 0.3462 - val_acc: 0.8360\n",
            "Epoch 65/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.2885 - acc: 0.8752 - val_loss: 0.3598 - val_acc: 0.8370\n",
            "Epoch 66/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.2881 - acc: 0.8770 - val_loss: 0.3661 - val_acc: 0.8280\n",
            "Epoch 67/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.2818 - acc: 0.8772 - val_loss: 0.3711 - val_acc: 0.8260\n",
            "Epoch 68/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2845 - acc: 0.8794 - val_loss: 0.3748 - val_acc: 0.8320\n",
            "Epoch 69/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2931 - acc: 0.8763 - val_loss: 0.3648 - val_acc: 0.8370\n",
            "Epoch 70/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.2888 - acc: 0.8774 - val_loss: 0.3669 - val_acc: 0.8380\n",
            "Epoch 71/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2816 - acc: 0.8801 - val_loss: 0.3703 - val_acc: 0.8230\n",
            "Epoch 72/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.2831 - acc: 0.8792 - val_loss: 0.3628 - val_acc: 0.8380\n",
            "Epoch 73/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2848 - acc: 0.8779 - val_loss: 0.3770 - val_acc: 0.8320\n",
            "Epoch 74/120\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 0.2809 - acc: 0.8805 - val_loss: 0.3632 - val_acc: 0.8360\n",
            "Epoch 75/120\n",
            "10000/10000 [==============================] - 5s 518us/step - loss: 0.2806 - acc: 0.8784 - val_loss: 0.3658 - val_acc: 0.8360\n",
            "Epoch 76/120\n",
            "10000/10000 [==============================] - 5s 504us/step - loss: 0.2778 - acc: 0.8823 - val_loss: 0.3679 - val_acc: 0.8350\n",
            "Epoch 77/120\n",
            "10000/10000 [==============================] - 6s 552us/step - loss: 0.2690 - acc: 0.8836 - val_loss: 0.4093 - val_acc: 0.8290\n",
            "Epoch 78/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2778 - acc: 0.8824 - val_loss: 0.3650 - val_acc: 0.8290\n",
            "Epoch 79/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.2757 - acc: 0.8821 - val_loss: 0.3752 - val_acc: 0.8250\n",
            "Epoch 80/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.2751 - acc: 0.8819 - val_loss: 0.3604 - val_acc: 0.8290\n",
            "Epoch 81/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2741 - acc: 0.8847 - val_loss: 0.4178 - val_acc: 0.8290\n",
            "Epoch 82/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.2705 - acc: 0.8842 - val_loss: 0.3796 - val_acc: 0.8290\n",
            "Epoch 83/120\n",
            "10000/10000 [==============================] - 4s 446us/step - loss: 0.2720 - acc: 0.8835 - val_loss: 0.3816 - val_acc: 0.8270\n",
            "Epoch 84/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.2705 - acc: 0.8833 - val_loss: 0.3930 - val_acc: 0.8270\n",
            "Epoch 85/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.2718 - acc: 0.8830 - val_loss: 0.3778 - val_acc: 0.8340\n",
            "Epoch 86/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.2658 - acc: 0.8874 - val_loss: 0.3813 - val_acc: 0.8340\n",
            "Epoch 87/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.2658 - acc: 0.8869 - val_loss: 0.3870 - val_acc: 0.8350\n",
            "Epoch 88/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2672 - acc: 0.8873 - val_loss: 0.4102 - val_acc: 0.8250\n",
            "Epoch 89/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.2691 - acc: 0.8849 - val_loss: 0.3924 - val_acc: 0.8270\n",
            "Epoch 90/120\n",
            "10000/10000 [==============================] - 4s 446us/step - loss: 0.2671 - acc: 0.8846 - val_loss: 0.3851 - val_acc: 0.8300\n",
            "Epoch 91/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2599 - acc: 0.8853 - val_loss: 0.3778 - val_acc: 0.8330\n",
            "Epoch 92/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.2672 - acc: 0.8877 - val_loss: 0.3907 - val_acc: 0.8330\n",
            "Epoch 93/120\n",
            "10000/10000 [==============================] - 5s 475us/step - loss: 0.2593 - acc: 0.8875 - val_loss: 0.4091 - val_acc: 0.8320\n",
            "Epoch 94/120\n",
            "10000/10000 [==============================] - 5s 504us/step - loss: 0.2592 - acc: 0.8883 - val_loss: 0.3912 - val_acc: 0.8320\n",
            "Epoch 95/120\n",
            "10000/10000 [==============================] - 5s 482us/step - loss: 0.2598 - acc: 0.8911 - val_loss: 0.4075 - val_acc: 0.8380\n",
            "Epoch 96/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2519 - acc: 0.8919 - val_loss: 0.4152 - val_acc: 0.8300\n",
            "Epoch 97/120\n",
            "10000/10000 [==============================] - 5s 497us/step - loss: 0.2547 - acc: 0.8934 - val_loss: 0.3951 - val_acc: 0.8320\n",
            "Epoch 98/120\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 0.2529 - acc: 0.8931 - val_loss: 0.4491 - val_acc: 0.8330\n",
            "Epoch 99/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.2602 - acc: 0.8856 - val_loss: 0.3983 - val_acc: 0.8320\n",
            "Epoch 100/120\n",
            "10000/10000 [==============================] - 4s 448us/step - loss: 0.2504 - acc: 0.8923 - val_loss: 0.4193 - val_acc: 0.8320\n",
            "Epoch 101/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2565 - acc: 0.8958 - val_loss: 0.4282 - val_acc: 0.8310\n",
            "Epoch 102/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2506 - acc: 0.8934 - val_loss: 0.4486 - val_acc: 0.8320\n",
            "Epoch 103/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.2535 - acc: 0.8945 - val_loss: 0.3987 - val_acc: 0.8300\n",
            "Epoch 104/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.2489 - acc: 0.8935 - val_loss: 0.4488 - val_acc: 0.8290\n",
            "Epoch 105/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.2501 - acc: 0.8941 - val_loss: 0.4432 - val_acc: 0.8300\n",
            "Epoch 106/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.2468 - acc: 0.8955 - val_loss: 0.3973 - val_acc: 0.8300\n",
            "Epoch 107/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2520 - acc: 0.8940 - val_loss: 0.4180 - val_acc: 0.8310\n",
            "Epoch 108/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.2498 - acc: 0.8979 - val_loss: 0.4381 - val_acc: 0.8250\n",
            "Epoch 109/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2403 - acc: 0.8986 - val_loss: 0.4398 - val_acc: 0.8310\n",
            "Epoch 110/120\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.2440 - acc: 0.8998 - val_loss: 0.4087 - val_acc: 0.8320\n",
            "Epoch 111/120\n",
            "10000/10000 [==============================] - 5s 503us/step - loss: 0.2410 - acc: 0.8998 - val_loss: 0.4180 - val_acc: 0.8280\n",
            "Epoch 112/120\n",
            "10000/10000 [==============================] - 5s 503us/step - loss: 0.2459 - acc: 0.8966 - val_loss: 0.4111 - val_acc: 0.8320\n",
            "Epoch 113/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.2438 - acc: 0.8998 - val_loss: 0.4094 - val_acc: 0.8290\n",
            "Epoch 114/120\n",
            "10000/10000 [==============================] - 5s 450us/step - loss: 0.2447 - acc: 0.8954 - val_loss: 0.4503 - val_acc: 0.8280\n",
            "Epoch 115/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2416 - acc: 0.9006 - val_loss: 0.4314 - val_acc: 0.8230\n",
            "Epoch 116/120\n",
            "10000/10000 [==============================] - 4s 449us/step - loss: 0.2399 - acc: 0.8997 - val_loss: 0.4300 - val_acc: 0.8370\n",
            "Epoch 117/120\n",
            "10000/10000 [==============================] - 5s 458us/step - loss: 0.2330 - acc: 0.9034 - val_loss: 0.4392 - val_acc: 0.8270\n",
            "Epoch 118/120\n",
            "10000/10000 [==============================] - 5s 485us/step - loss: 0.2407 - acc: 0.9000 - val_loss: 0.4249 - val_acc: 0.8340\n",
            "Epoch 119/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2300 - acc: 0.9061 - val_loss: 0.4428 - val_acc: 0.8240\n",
            "Epoch 120/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.2344 - acc: 0.9022 - val_loss: 0.4461 - val_acc: 0.8310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CxLmYjDM0Sl_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving the model\n",
        "----\n"
      ]
    },
    {
      "metadata": {
        "id": "u9ZpXSka0V8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "47x9j9so0e47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model\n",
        "----\n"
      ]
    },
    {
      "metadata": {
        "id": "19Ui5EMl0h8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "3ed140cd-c43f-497c-bf01-464f0aa61170"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npKCUUqqRJgWllFKNNCkopZRq9P/GhcOZa2jvXQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "54RctKdC1DUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3C2sdjDz1M2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d3f854cd-7453-47a3-c701-a619f5626e47"
      },
      "cell_type": "code",
      "source": [
        "story =' '.join(word for word in test_data[10][0])\n",
        "print(story)\n",
        "\n",
        "query = ' '.join(word for word in test_data[10][1])\n",
        "print(query)\n",
        "\n",
        "print(\"True Test Answer from Data is:\",test_data[10][2])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "John moved to the hallway . Sandra went to the bedroom .\n",
            "Is John in the hallway ?\n",
            "True Test Answer from Data is: yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzSbvaLb1ajj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "56c20d25-077e-46ab-b3e2-84f3e8faeed9"
      },
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[10])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[10][val_max])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.68367696\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}